{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3abd7a3d-5bf5-45fb-8c94-ae4c37ed2b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DhaidahO\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Activation\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import MeanSquaredError, MeanAbsoluteError, MeanAbsolutePercentageError\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ce005dc-7463-42cd-9d89-01436701e480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow 2.15.0\n",
      "Uninstalling tensorflow-2.15.0:\n",
      "  Successfully uninstalled tensorflow-2.15.0\n",
      "Collecting tensorflow==2.15.0\n",
      "  Using cached tensorflow-2.15.0-cp311-cp311-win_amd64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow==2.15.0) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (3.20.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (4.9.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow==2.15.0) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.29.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\dhaidaho\\appdata\\local\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15.0) (3.2.2)\n",
      "Using cached tensorflow-2.15.0-cp311-cp311-win_amd64.whl (2.1 kB)\n",
      "Installing collected packages: tensorflow\n",
      "Successfully installed tensorflow-2.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y tensorflow\n",
    "!pip install tensorflow==2.15.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85854520-eb84-45da-a7ef-cc7ba98278af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_Data = pd.read_csv('./SWaT dataset/SWaT_Dataset_Normal_v0.csv')\n",
    "Attack_Data = pd.read_csv('./SWaT dataset/SWaT_Dataset_Attack_v0.csv')\n",
    "\n",
    "df = pd.concat([Normal_Data, Attack_Data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e59e1fa-f975-418e-9b18-95064b3aa5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(946719, 53)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40519f84-7b65-4669-9f3f-759a95ccd5fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>FIT101</th>\n",
       "      <th>LIT101</th>\n",
       "      <th>MV101</th>\n",
       "      <th>P101</th>\n",
       "      <th>P102</th>\n",
       "      <th>AIT201</th>\n",
       "      <th>AIT202</th>\n",
       "      <th>AIT203</th>\n",
       "      <th>FIT201</th>\n",
       "      <th>...</th>\n",
       "      <th>P501</th>\n",
       "      <th>P502</th>\n",
       "      <th>PIT501</th>\n",
       "      <th>PIT502</th>\n",
       "      <th>PIT503</th>\n",
       "      <th>FIT601</th>\n",
       "      <th>P601</th>\n",
       "      <th>P602</th>\n",
       "      <th>P603</th>\n",
       "      <th>Normal/Attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22/12/2015 4:00:00 PM</td>\n",
       "      <td>2.470294</td>\n",
       "      <td>261.5804</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>244.3284</td>\n",
       "      <td>8.19008</td>\n",
       "      <td>306.101</td>\n",
       "      <td>2.471278</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.02948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.277749</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22/12/2015 4:00:01 PM</td>\n",
       "      <td>2.457163</td>\n",
       "      <td>261.1879</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>244.3284</td>\n",
       "      <td>8.19008</td>\n",
       "      <td>306.101</td>\n",
       "      <td>2.468587</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.02948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.277749</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22/12/2015 4:00:02 PM</td>\n",
       "      <td>2.439548</td>\n",
       "      <td>260.9131</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>244.3284</td>\n",
       "      <td>8.19008</td>\n",
       "      <td>306.101</td>\n",
       "      <td>2.467305</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.02948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.277749</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22/12/2015 4:00:03 PM</td>\n",
       "      <td>2.428338</td>\n",
       "      <td>260.2850</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>244.3284</td>\n",
       "      <td>8.19008</td>\n",
       "      <td>306.101</td>\n",
       "      <td>2.466536</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.02948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.277749</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22/12/2015 4:00:04 PM</td>\n",
       "      <td>2.424815</td>\n",
       "      <td>259.8925</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>244.4245</td>\n",
       "      <td>8.19008</td>\n",
       "      <td>306.101</td>\n",
       "      <td>2.466536</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.02948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.277749</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Timestamp    FIT101    LIT101  MV101  P101  P102    AIT201  \\\n",
       "0   22/12/2015 4:00:00 PM  2.470294  261.5804      2     2     1  244.3284   \n",
       "1   22/12/2015 4:00:01 PM  2.457163  261.1879      2     2     1  244.3284   \n",
       "2   22/12/2015 4:00:02 PM  2.439548  260.9131      2     2     1  244.3284   \n",
       "3   22/12/2015 4:00:03 PM  2.428338  260.2850      2     2     1  244.3284   \n",
       "4   22/12/2015 4:00:04 PM  2.424815  259.8925      2     2     1  244.4245   \n",
       "\n",
       "    AIT202   AIT203    FIT201  ...  P501  P502    PIT501  PIT502    PIT503  \\\n",
       "0  8.19008  306.101  2.471278  ...     1     1  10.02948     0.0  4.277749   \n",
       "1  8.19008  306.101  2.468587  ...     1     1  10.02948     0.0  4.277749   \n",
       "2  8.19008  306.101  2.467305  ...     1     1  10.02948     0.0  4.277749   \n",
       "3  8.19008  306.101  2.466536  ...     1     1  10.02948     0.0  4.277749   \n",
       "4  8.19008  306.101  2.466536  ...     1     1  10.02948     0.0  4.277749   \n",
       "\n",
       "     FIT601  P601  P602  P603  Normal/Attack  \n",
       "0  0.000256     1     1     1         Normal  \n",
       "1  0.000256     1     1     1         Normal  \n",
       "2  0.000256     1     1     1         Normal  \n",
       "3  0.000256     1     1     1         Normal  \n",
       "4  0.000256     1     1     1         Normal  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27e6d3ea-8007-4d8a-bb6a-61ea092c92c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 946719 entries, 0 to 449918\n",
      "Data columns (total 53 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   Timestamp      946719 non-null  object \n",
      " 1   FIT101         946719 non-null  float64\n",
      " 2   LIT101         946719 non-null  float64\n",
      " 3   MV101          946719 non-null  int64  \n",
      " 4   P101           946719 non-null  int64  \n",
      " 5   P102           946719 non-null  int64  \n",
      " 6   AIT201         946719 non-null  float64\n",
      " 7   AIT202         946719 non-null  float64\n",
      " 8   AIT203         946719 non-null  float64\n",
      " 9   FIT201         946719 non-null  float64\n",
      " 10  MV201          946719 non-null  int64  \n",
      " 11  P201           946719 non-null  int64  \n",
      " 12  P202           946719 non-null  int64  \n",
      " 13  P203           946719 non-null  int64  \n",
      " 14  P204           946719 non-null  int64  \n",
      " 15  P205           946719 non-null  int64  \n",
      " 16  P206           946719 non-null  int64  \n",
      " 17  DPIT301        946719 non-null  float64\n",
      " 18  FIT301         946719 non-null  float64\n",
      " 19  LIT301         946719 non-null  float64\n",
      " 20  MV301          946719 non-null  int64  \n",
      " 21  MV302          946719 non-null  int64  \n",
      " 22  MV303          946719 non-null  int64  \n",
      " 23  MV304          946719 non-null  int64  \n",
      " 24  P301           946719 non-null  int64  \n",
      " 25  P302           946719 non-null  int64  \n",
      " 26  AIT401         946719 non-null  float64\n",
      " 27  AIT402         946719 non-null  float64\n",
      " 28  FIT401         946719 non-null  float64\n",
      " 29  LIT401         946719 non-null  float64\n",
      " 30  P401           946719 non-null  int64  \n",
      " 31  P402           946719 non-null  int64  \n",
      " 32  P403           946719 non-null  int64  \n",
      " 33  P404           946719 non-null  int64  \n",
      " 34  UV401          946719 non-null  int64  \n",
      " 35  AIT501         946719 non-null  float64\n",
      " 36  AIT502         946719 non-null  float64\n",
      " 37  AIT503         946719 non-null  float64\n",
      " 38  AIT504         946719 non-null  float64\n",
      " 39  FIT501         946719 non-null  float64\n",
      " 40  FIT502         946719 non-null  float64\n",
      " 41  FIT503         946719 non-null  float64\n",
      " 42  FIT504         946719 non-null  float64\n",
      " 43  P501           946719 non-null  int64  \n",
      " 44  P502           946719 non-null  int64  \n",
      " 45  PIT501         946719 non-null  float64\n",
      " 46  PIT502         946719 non-null  float64\n",
      " 47  PIT503         946719 non-null  float64\n",
      " 48  FIT601         946719 non-null  float64\n",
      " 49  P601           946719 non-null  int64  \n",
      " 50  P602           946719 non-null  int64  \n",
      " 51  P603           946719 non-null  int64  \n",
      " 52  Normal/Attack  946719 non-null  object \n",
      "dtypes: float64(25), int64(26), object(2)\n",
      "memory usage: 390.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e173d75-a5a3-4c35-a46b-4777e3d9f8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Normal', 'Attack', 'A ttack'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Normal/Attack'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "865a69d2-d6e9-4bd1-aaa3-fff6fd8a22a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Normal/Attack'] = df['Normal/Attack'].str.replace(' ', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cdae7f7-cb1a-4860-8a95-f771b1fb9ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Timestamp    FIT101    LIT101  MV101  P101  P102    AIT201  \\\n",
      "0   22/12/2015 4:00:00 PM  2.470294  261.5804      2     2     1  244.3284   \n",
      "1   22/12/2015 4:00:01 PM  2.457163  261.1879      2     2     1  244.3284   \n",
      "2   22/12/2015 4:00:02 PM  2.439548  260.9131      2     2     1  244.3284   \n",
      "3   22/12/2015 4:00:03 PM  2.428338  260.2850      2     2     1  244.3284   \n",
      "4   22/12/2015 4:00:04 PM  2.424815  259.8925      2     2     1  244.4245   \n",
      "\n",
      "    AIT202   AIT203    FIT201  ...  P501  P502    PIT501  PIT502    PIT503  \\\n",
      "0  8.19008  306.101  2.471278  ...     1     1  10.02948     0.0  4.277749   \n",
      "1  8.19008  306.101  2.468587  ...     1     1  10.02948     0.0  4.277749   \n",
      "2  8.19008  306.101  2.467305  ...     1     1  10.02948     0.0  4.277749   \n",
      "3  8.19008  306.101  2.466536  ...     1     1  10.02948     0.0  4.277749   \n",
      "4  8.19008  306.101  2.466536  ...     1     1  10.02948     0.0  4.277749   \n",
      "\n",
      "     FIT601  P601  P602  P603  Normal/Attack  \n",
      "0  0.000256     1     1     1         Normal  \n",
      "1  0.000256     1     1     1         Normal  \n",
      "2  0.000256     1     1     1         Normal  \n",
      "3  0.000256     1     1     1         Normal  \n",
      "4  0.000256     1     1     1         Normal  \n",
      "\n",
      "[5 rows x 53 columns]\n",
      "'Timestamp' in df.columns: True\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(\"'Timestamp' in df.columns:\", 'Timestamp' in df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0beecfb4-2df2-4cdd-95c7-cd3653a5ed32",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Timestamp' in df.columns:\n",
    "    df['Timestamp'] = df['Timestamp'].str.strip()\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%d/%m/%Y %I:%M:%S %p')\n",
    "    df = df.set_index('Timestamp')\n",
    "else:\n",
    "    print(\"'Timestamp' column not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a45d90d-42e0-488a-a840-324c2bdd9aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "791016c5-9a17-4b1a-9f8e-1b6a89c6e71c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIT101</th>\n",
       "      <th>LIT101</th>\n",
       "      <th>MV101</th>\n",
       "      <th>P101</th>\n",
       "      <th>P102</th>\n",
       "      <th>AIT201</th>\n",
       "      <th>AIT202</th>\n",
       "      <th>AIT203</th>\n",
       "      <th>FIT201</th>\n",
       "      <th>MV201</th>\n",
       "      <th>...</th>\n",
       "      <th>P501</th>\n",
       "      <th>P502</th>\n",
       "      <th>PIT501</th>\n",
       "      <th>PIT502</th>\n",
       "      <th>PIT503</th>\n",
       "      <th>FIT601</th>\n",
       "      <th>P601</th>\n",
       "      <th>P602</th>\n",
       "      <th>P603</th>\n",
       "      <th>Normal/Attack</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-12-22 16:00:00</th>\n",
       "      <td>2.470294</td>\n",
       "      <td>261.5804</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>244.3284</td>\n",
       "      <td>8.190080</td>\n",
       "      <td>306.1010</td>\n",
       "      <td>2.471278</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.02948</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.277749</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-22 16:00:01</th>\n",
       "      <td>2.457163</td>\n",
       "      <td>261.1879</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>244.3284</td>\n",
       "      <td>8.190080</td>\n",
       "      <td>306.1010</td>\n",
       "      <td>2.468587</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.02948</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.277749</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-22 16:00:02</th>\n",
       "      <td>2.439548</td>\n",
       "      <td>260.9131</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>244.3284</td>\n",
       "      <td>8.190080</td>\n",
       "      <td>306.1010</td>\n",
       "      <td>2.467305</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.02948</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.277749</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-22 16:00:03</th>\n",
       "      <td>2.428338</td>\n",
       "      <td>260.2850</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>244.3284</td>\n",
       "      <td>8.190080</td>\n",
       "      <td>306.1010</td>\n",
       "      <td>2.466536</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.02948</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.277749</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-22 16:00:04</th>\n",
       "      <td>2.424815</td>\n",
       "      <td>259.8925</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>244.4245</td>\n",
       "      <td>8.190080</td>\n",
       "      <td>306.1010</td>\n",
       "      <td>2.466536</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.02948</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.277749</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02 14:59:50</th>\n",
       "      <td>2.633956</td>\n",
       "      <td>516.8018</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>168.0979</td>\n",
       "      <td>8.642528</td>\n",
       "      <td>301.8457</td>\n",
       "      <td>2.462051</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>251.37790</td>\n",
       "      <td>0.945119</td>\n",
       "      <td>189.118200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02 14:59:51</th>\n",
       "      <td>2.626909</td>\n",
       "      <td>516.9588</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>168.0979</td>\n",
       "      <td>8.642528</td>\n",
       "      <td>301.8457</td>\n",
       "      <td>2.460898</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>251.37790</td>\n",
       "      <td>0.945119</td>\n",
       "      <td>189.118200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02 14:59:52</th>\n",
       "      <td>2.616340</td>\n",
       "      <td>517.4691</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>168.0979</td>\n",
       "      <td>8.642528</td>\n",
       "      <td>301.9226</td>\n",
       "      <td>2.460770</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>251.37790</td>\n",
       "      <td>0.945119</td>\n",
       "      <td>189.118200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02 14:59:53</th>\n",
       "      <td>2.606091</td>\n",
       "      <td>518.1757</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>168.0979</td>\n",
       "      <td>8.639965</td>\n",
       "      <td>301.9226</td>\n",
       "      <td>2.459488</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>251.37790</td>\n",
       "      <td>0.945119</td>\n",
       "      <td>189.118200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02 14:59:54</th>\n",
       "      <td>2.586555</td>\n",
       "      <td>518.9607</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>168.0979</td>\n",
       "      <td>8.638683</td>\n",
       "      <td>301.9226</td>\n",
       "      <td>2.459488</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>251.37790</td>\n",
       "      <td>0.865024</td>\n",
       "      <td>189.118200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>928893 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       FIT101    LIT101  MV101  P101  P102    AIT201  \\\n",
       "Timestamp                                                              \n",
       "2015-12-22 16:00:00  2.470294  261.5804      2     2     1  244.3284   \n",
       "2015-12-22 16:00:01  2.457163  261.1879      2     2     1  244.3284   \n",
       "2015-12-22 16:00:02  2.439548  260.9131      2     2     1  244.3284   \n",
       "2015-12-22 16:00:03  2.428338  260.2850      2     2     1  244.3284   \n",
       "2015-12-22 16:00:04  2.424815  259.8925      2     2     1  244.4245   \n",
       "...                       ...       ...    ...   ...   ...       ...   \n",
       "2016-01-02 14:59:50  2.633956  516.8018      2     2     1  168.0979   \n",
       "2016-01-02 14:59:51  2.626909  516.9588      2     2     1  168.0979   \n",
       "2016-01-02 14:59:52  2.616340  517.4691      2     2     1  168.0979   \n",
       "2016-01-02 14:59:53  2.606091  518.1757      2     2     1  168.0979   \n",
       "2016-01-02 14:59:54  2.586555  518.9607      2     2     1  168.0979   \n",
       "\n",
       "                       AIT202    AIT203    FIT201  MV201  ...  P501  P502  \\\n",
       "Timestamp                                                 ...               \n",
       "2015-12-22 16:00:00  8.190080  306.1010  2.471278      2  ...     1     1   \n",
       "2015-12-22 16:00:01  8.190080  306.1010  2.468587      2  ...     1     1   \n",
       "2015-12-22 16:00:02  8.190080  306.1010  2.467305      2  ...     1     1   \n",
       "2015-12-22 16:00:03  8.190080  306.1010  2.466536      2  ...     1     1   \n",
       "2015-12-22 16:00:04  8.190080  306.1010  2.466536      2  ...     1     1   \n",
       "...                       ...       ...       ...    ...  ...   ...   ...   \n",
       "2016-01-02 14:59:50  8.642528  301.8457  2.462051      2  ...     2     1   \n",
       "2016-01-02 14:59:51  8.642528  301.8457  2.460898      2  ...     2     1   \n",
       "2016-01-02 14:59:52  8.642528  301.9226  2.460770      2  ...     2     1   \n",
       "2016-01-02 14:59:53  8.639965  301.9226  2.459488      2  ...     2     1   \n",
       "2016-01-02 14:59:54  8.638683  301.9226  2.459488      2  ...     2     1   \n",
       "\n",
       "                        PIT501    PIT502      PIT503    FIT601  P601  P602  \\\n",
       "Timestamp                                                                    \n",
       "2015-12-22 16:00:00   10.02948  0.000000    4.277749  0.000256     1     1   \n",
       "2015-12-22 16:00:01   10.02948  0.000000    4.277749  0.000256     1     1   \n",
       "2015-12-22 16:00:02   10.02948  0.000000    4.277749  0.000256     1     1   \n",
       "2015-12-22 16:00:03   10.02948  0.000000    4.277749  0.000256     1     1   \n",
       "2015-12-22 16:00:04   10.02948  0.000000    4.277749  0.000256     1     1   \n",
       "...                        ...       ...         ...       ...   ...   ...   \n",
       "2016-01-02 14:59:50  251.37790  0.945119  189.118200  0.000000     1     1   \n",
       "2016-01-02 14:59:51  251.37790  0.945119  189.118200  0.000000     1     1   \n",
       "2016-01-02 14:59:52  251.37790  0.945119  189.118200  0.000000     1     1   \n",
       "2016-01-02 14:59:53  251.37790  0.945119  189.118200  0.000000     1     1   \n",
       "2016-01-02 14:59:54  251.37790  0.865024  189.118200  0.000000     1     1   \n",
       "\n",
       "                     P603  Normal/Attack  \n",
       "Timestamp                                 \n",
       "2015-12-22 16:00:00     1         Normal  \n",
       "2015-12-22 16:00:01     1         Normal  \n",
       "2015-12-22 16:00:02     1         Normal  \n",
       "2015-12-22 16:00:03     1         Normal  \n",
       "2015-12-22 16:00:04     1         Normal  \n",
       "...                   ...            ...  \n",
       "2016-01-02 14:59:50     1         Normal  \n",
       "2016-01-02 14:59:51     1         Normal  \n",
       "2016-01-02 14:59:52     1         Normal  \n",
       "2016-01-02 14:59:53     1         Normal  \n",
       "2016-01-02 14:59:54     1         Normal  \n",
       "\n",
       "[928893 rows x 52 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e67c712a-a3a9-4102-93da-fab94f78d947",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb85c95a-f9e9-47b1-bcdf-192cb65f0f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FIT101            3953\n",
       "LIT101           12162\n",
       "MV101                3\n",
       "P101                 2\n",
       "P102                 2\n",
       "AIT201            2338\n",
       "AIT202            1763\n",
       "AIT203            6868\n",
       "FIT201            4989\n",
       "MV201                3\n",
       "P201                 2\n",
       "P202                 1\n",
       "P203                 2\n",
       "P204                 2\n",
       "P205                 2\n",
       "P206                 2\n",
       "DPIT301           5180\n",
       "FIT301            8281\n",
       "LIT301           11966\n",
       "MV301                3\n",
       "MV302                3\n",
       "MV303                3\n",
       "MV304                3\n",
       "P301                 2\n",
       "P302                 2\n",
       "AIT401              37\n",
       "AIT402            4127\n",
       "FIT401             968\n",
       "LIT401           15141\n",
       "P401                 1\n",
       "P402                 2\n",
       "P403                 2\n",
       "P404                 1\n",
       "UV401                2\n",
       "AIT501            1724\n",
       "AIT502            3470\n",
       "AIT503            1123\n",
       "AIT504             565\n",
       "FIT501            1027\n",
       "FIT502            1560\n",
       "FIT503             499\n",
       "FIT504             289\n",
       "P501                 2\n",
       "P502                 1\n",
       "PIT501            1419\n",
       "PIT502             115\n",
       "PIT503            1334\n",
       "FIT601            6043\n",
       "P601                 1\n",
       "P602                 2\n",
       "P603                 1\n",
       "Normal/Attack        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e43af500-6d36-4553-bf93-aa12b9e5779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, df.nunique() > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d479555e-fe96-4a4c-8680-e78d8432a030",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5d38408-4643-4059-abe8-cce577365411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal/Attack\n",
      "Normal    875250\n",
      "Attack     53648\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_counts = df['Normal/Attack'].value_counts()\n",
    "print(class_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61104f2a-ba90-4915-bb70-99af284a079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Normal/Attack'] = df['Normal/Attack'].apply(lambda x: 1 if x == 'Attack' else 0)\n",
    "target_feature = df['Normal/Attack']\n",
    "X = df.drop(columns=['Normal/Attack'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a786b9c3-d7a9-46c7-afce-2878f8c4b4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cardinality_threshold = 8\n",
    "num_features = [column for column in X.columns if X[column].nunique() > cardinality_threshold]\n",
    "catg_features = [column for column in X.columns if X[column].nunique() <= cardinality_threshold]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68690caf-9dc6-4b08-8813-3d7a7ae78896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (743118, 51)\n",
      "Test data shape: (185780, 51)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "X_encoded = encoder.fit_transform(X[catg_features])\n",
    "catg_features_names = encoder.get_feature_names_out(catg_features)\n",
    "X_combined = pd.concat([pd.DataFrame(X_encoded, columns=catg_features_names), X[num_features].reset_index(drop=True)], axis=1) if num_features else pd.DataFrame(X_encoded, columns=catg_features_names)\n",
    "X_train, X_test, target_train, target_test = train_test_split(X_combined, target_feature, test_size=0.2, random_state=42, stratify=target_feature)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "if num_features:\n",
    "    X_train[num_features] = scaler.fit_transform(X_train[num_features])\n",
    "    X_test[num_features] = scaler.transform(X_test[num_features])\n",
    "df_test= X_test\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Test data shape:\", df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b02dfa9-f7e1-4969-b748-e434314739c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in training data:\n",
      " Normal/Attack\n",
      "0    700200\n",
      "1     42918\n",
      "Name: count, dtype: int64\n",
      "Class distribution in training data:\n",
      " Normal/Attack\n",
      "0    175050\n",
      "1     10730\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_distribution = target_train.value_counts()\n",
    "print(\"Class distribution in training data:\\n\", class_distribution)\n",
    "class_distribution2 = target_test.value_counts()\n",
    "print(\"Class distribution in training data:\\n\", class_distribution2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63128517-b069-49d2-8e52-0cb4aa44aef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal/Attack\n",
      "0    280000\n",
      "1     42918\n",
      "Name: count, dtype: int64\n",
      "Resampled training set shape: (322918, 51)\n",
      "Resampled class distribution: Normal/Attack\n",
      "0    280000\n",
      "1     42918\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import pandas as pd\n",
    "sampling_strategy = {0: 280000, 1: 42918}\n",
    "undersampler = RandomUnderSampler(sampling_strategy=sampling_strategy, random_state=42)\n",
    "df_train, target_train = undersampler.fit_resample(X_train, target_train)\n",
    "print(pd.Series(target_train).value_counts())\n",
    "\n",
    "print('Resampled training set shape:', df_train.shape)\n",
    "print('Resampled class distribution:', pd.Series(target_train).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b429b136-e58f-42a0-844e-32c0c57044b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reshaped1 = np.reshape(df_train, (df_train.shape[0], 1, df_train.shape[1]))\n",
    "X_test_reshaped1 = np.reshape(df_test, (df_test.shape[0], 1, df_test.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c08fff7-4f2a-4d94-89d8-dea84ba2c0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with 30 LSTM cells, dropout = 0, and learning rate = 0.001...\n",
      "WARNING:tensorflow:From C:\\Users\\DhaidahO\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py:148: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:From C:\\Users\\DhaidahO\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\DhaidahO\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1615/1615 [==============================] - 19s 8ms/step - loss: 0.0227 - mse: 0.0227 - mae: 0.0440 - val_loss: 0.0086 - val_mse: 0.0086 - val_mae: 0.0201\n",
      "Epoch 2/15\n",
      "1615/1615 [==============================] - 12s 8ms/step - loss: 0.0146 - mse: 0.0146 - mae: 0.0255 - val_loss: 0.0106 - val_mse: 0.0106 - val_mae: 0.0269\n",
      "Epoch 3/15\n",
      "1615/1615 [==============================] - 10s 6ms/step - loss: 0.0133 - mse: 0.0133 - mae: 0.0228 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0105\n",
      "Epoch 4/15\n",
      "1615/1615 [==============================] - 10s 6ms/step - loss: 0.0126 - mse: 0.0126 - mae: 0.0211 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0091\n",
      "Epoch 5/15\n",
      "1615/1615 [==============================] - 10s 6ms/step - loss: 0.0121 - mse: 0.0121 - mae: 0.0200 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0109\n",
      "Epoch 6/15\n",
      "1615/1615 [==============================] - 10s 6ms/step - loss: 0.0118 - mse: 0.0118 - mae: 0.0192 - val_loss: 0.0071 - val_mse: 0.0071 - val_mae: 0.0149\n",
      "Epoch 7/15\n",
      "1615/1615 [==============================] - 12s 7ms/step - loss: 0.0113 - mse: 0.0113 - mae: 0.0185 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0085\n",
      "Epoch 8/15\n",
      "1615/1615 [==============================] - 12s 7ms/step - loss: 0.0109 - mse: 0.0109 - mae: 0.0177 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0084\n",
      "Epoch 9/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0108 - mse: 0.0108 - mae: 0.0172 - val_loss: 0.0050 - val_mse: 0.0050 - val_mae: 0.0084\n",
      "Epoch 10/15\n",
      "1615/1615 [==============================] - 11s 7ms/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0167 - val_loss: 0.0054 - val_mse: 0.0054 - val_mae: 0.0104\n",
      "Epoch 11/15\n",
      "1615/1615 [==============================] - 10s 6ms/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0163 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0098\n",
      "Epoch 12/15\n",
      "1615/1615 [==============================] - 11s 7ms/step - loss: 0.0102 - mse: 0.0102 - mae: 0.0158 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0116\n",
      "Epoch 13/15\n",
      "1615/1615 [==============================] - 11s 7ms/step - loss: 0.0100 - mse: 0.0100 - mae: 0.0155 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0099\n",
      "Epoch 14/15\n",
      "1615/1615 [==============================] - 10s 6ms/step - loss: 0.0099 - mse: 0.0099 - mae: 0.0152 - val_loss: 0.0046 - val_mse: 0.0046 - val_mae: 0.0071\n",
      "Epoch 15/15\n",
      "1615/1615 [==============================] - 11s 7ms/step - loss: 0.0098 - mse: 0.0098 - mae: 0.0149 - val_loss: 0.0045 - val_mse: 0.0045 - val_mae: 0.0081\n",
      "Train MSE = 0.011764910072088242, Validation MSE = 0.007067084778100252, Train MAE = 0.019222483038902283, Validation MAE = 0.014864531345665455, Train RMSE = 0.10846617017341509, Validation RMSE = 0.08406595492885484\n",
      "Running with 30 LSTM cells, dropout = 0, and learning rate = 0.01...\n",
      "Epoch 1/15\n",
      "1615/1615 [==============================] - 21s 8ms/step - loss: 0.0196 - mse: 0.0196 - mae: 0.0283 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0094\n",
      "Epoch 2/15\n",
      "1615/1615 [==============================] - 11s 7ms/step - loss: 0.0137 - mse: 0.0137 - mae: 0.0192 - val_loss: 0.0077 - val_mse: 0.0077 - val_mae: 0.0157\n",
      "Epoch 3/15\n",
      "1615/1615 [==============================] - 10s 6ms/step - loss: 0.0126 - mse: 0.0126 - mae: 0.0172 - val_loss: 0.0077 - val_mse: 0.0077 - val_mae: 0.0127\n",
      "Epoch 4/15\n",
      "1615/1615 [==============================] - 11s 7ms/step - loss: 0.0120 - mse: 0.0120 - mae: 0.0162 - val_loss: 0.0054 - val_mse: 0.0054 - val_mae: 0.0070\n",
      "Epoch 5/15\n",
      "1615/1615 [==============================] - 10s 6ms/step - loss: 0.0117 - mse: 0.0117 - mae: 0.0156 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0084\n",
      "Epoch 6/15\n",
      "1615/1615 [==============================] - 14s 9ms/step - loss: 0.0115 - mse: 0.0115 - mae: 0.0152 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0070\n",
      "Epoch 7/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0112 - mse: 0.0112 - mae: 0.0145 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0070\n",
      "Epoch 8/15\n",
      "1615/1615 [==============================] - 11s 7ms/step - loss: 0.0107 - mse: 0.0107 - mae: 0.0140 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0072\n",
      "Epoch 9/15\n",
      "1615/1615 [==============================] - 11s 7ms/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0140 - val_loss: 0.0049 - val_mse: 0.0049 - val_mae: 0.0068\n",
      "Epoch 10/15\n",
      "1615/1615 [==============================] - 11s 7ms/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0137 - val_loss: 0.0050 - val_mse: 0.0050 - val_mae: 0.0069\n",
      "Epoch 11/15\n",
      "1615/1615 [==============================] - 11s 7ms/step - loss: 0.0103 - mse: 0.0103 - mae: 0.0135 - val_loss: 0.0046 - val_mse: 0.0046 - val_mae: 0.0063\n",
      "Epoch 12/15\n",
      "1615/1615 [==============================] - 10s 6ms/step - loss: 0.0102 - mse: 0.0102 - mae: 0.0133 - val_loss: 0.0047 - val_mse: 0.0047 - val_mae: 0.0063\n",
      "Epoch 13/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0102 - mse: 0.0102 - mae: 0.0132 - val_loss: 0.0047 - val_mse: 0.0047 - val_mae: 0.0062\n",
      "Epoch 14/15\n",
      "1615/1615 [==============================] - 12s 8ms/step - loss: 0.0101 - mse: 0.0101 - mae: 0.0130 - val_loss: 0.0045 - val_mse: 0.0045 - val_mae: 0.0060\n",
      "Epoch 15/15\n",
      "1615/1615 [==============================] - 11s 7ms/step - loss: 0.0100 - mse: 0.0100 - mae: 0.0129 - val_loss: 0.0048 - val_mse: 0.0048 - val_mae: 0.0065\n",
      "Train MSE = 0.01152036152780056, Validation MSE = 0.005232466384768486, Train MAE = 0.0151703841984272, Validation MAE = 0.007027938961982727, Train RMSE = 0.10733294707498048, Validation RMSE = 0.07233578910033736\n",
      "Running with 30 LSTM cells, dropout = 0.01, and learning rate = 0.001...\n",
      "Epoch 1/15\n",
      "1615/1615 [==============================] - 20s 9ms/step - loss: 0.0238 - mse: 0.0238 - mae: 0.0441 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0259\n",
      "Epoch 2/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0162 - mse: 0.0162 - mae: 0.0263 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0104\n",
      "Epoch 3/15\n",
      "1615/1615 [==============================] - 12s 7ms/step - loss: 0.0149 - mse: 0.0149 - mae: 0.0240 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0091\n",
      "Epoch 4/15\n",
      "1615/1615 [==============================] - 15s 9ms/step - loss: 0.0141 - mse: 0.0141 - mae: 0.0226 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0147\n",
      "Epoch 5/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0134 - mse: 0.0134 - mae: 0.0213 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0106\n",
      "Epoch 6/15\n",
      "1615/1615 [==============================] - 12s 8ms/step - loss: 0.0128 - mse: 0.0128 - mae: 0.0203 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0116\n",
      "Epoch 7/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0125 - mse: 0.0125 - mae: 0.0197 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0121\n",
      "Epoch 8/15\n",
      "1615/1615 [==============================] - 12s 7ms/step - loss: 0.0123 - mse: 0.0123 - mae: 0.0191 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0091\n",
      "Epoch 9/15\n",
      "1615/1615 [==============================] - 12s 7ms/step - loss: 0.0121 - mse: 0.0121 - mae: 0.0187 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0090\n",
      "Epoch 10/15\n",
      "1615/1615 [==============================] - 15s 9ms/step - loss: 0.0119 - mse: 0.0119 - mae: 0.0182 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0084\n",
      "Epoch 11/15\n",
      "1615/1615 [==============================] - 12s 7ms/step - loss: 0.0118 - mse: 0.0118 - mae: 0.0178 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0096\n",
      "Epoch 12/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0116 - mse: 0.0116 - mae: 0.0173 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0074\n",
      "Epoch 13/15\n",
      "1615/1615 [==============================] - 16s 10ms/step - loss: 0.0115 - mse: 0.0115 - mae: 0.0170 - val_loss: 0.0053 - val_mse: 0.0053 - val_mae: 0.0081\n",
      "Epoch 14/15\n",
      "1615/1615 [==============================] - 16s 10ms/step - loss: 0.0114 - mse: 0.0114 - mae: 0.0166 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0073\n",
      "Epoch 15/15\n",
      "1615/1615 [==============================] - 18s 11ms/step - loss: 0.0114 - mse: 0.0114 - mae: 0.0164 - val_loss: 0.0050 - val_mse: 0.0050 - val_mae: 0.0070\n",
      "Train MSE = 0.012792163528501987, Validation MSE = 0.006322481203824282, Train MAE = 0.020292075350880623, Validation MAE = 0.011641965247690678, Train RMSE = 0.11310244704913323, Validation RMSE = 0.07951403149019852\n",
      "Running with 30 LSTM cells, dropout = 0.01, and learning rate = 0.01...\n",
      "Epoch 1/15\n",
      "1615/1615 [==============================] - 22s 9ms/step - loss: 0.0186 - mse: 0.0186 - mae: 0.0271 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0081\n",
      "Epoch 2/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0151 - mse: 0.0151 - mae: 0.0199 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0085\n",
      "Epoch 3/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0139 - mse: 0.0139 - mae: 0.0179 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0078\n",
      "Epoch 4/15\n",
      "1615/1615 [==============================] - 14s 8ms/step - loss: 0.0136 - mse: 0.0136 - mae: 0.0170 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0082\n",
      "Epoch 5/15\n",
      "1615/1615 [==============================] - 15s 9ms/step - loss: 0.0133 - mse: 0.0133 - mae: 0.0165 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0070\n",
      "Epoch 6/15\n",
      "1615/1615 [==============================] - 14s 9ms/step - loss: 0.0131 - mse: 0.0131 - mae: 0.0161 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0073\n",
      "Epoch 7/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0130 - mse: 0.0130 - mae: 0.0157 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0072\n",
      "Epoch 8/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0129 - mse: 0.0129 - mae: 0.0155 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0065\n",
      "Epoch 9/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0128 - mse: 0.0128 - mae: 0.0154 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0080\n",
      "Epoch 10/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0126 - mse: 0.0126 - mae: 0.0152 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0069\n",
      "Epoch 11/15\n",
      "1615/1615 [==============================] - 15s 9ms/step - loss: 0.0126 - mse: 0.0126 - mae: 0.0151 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0064\n",
      "Epoch 12/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0125 - mse: 0.0125 - mae: 0.0151 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0062\n",
      "Epoch 13/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0124 - mse: 0.0124 - mae: 0.0150 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0064\n",
      "Epoch 14/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0124 - mse: 0.0124 - mae: 0.0148 - val_loss: 0.0054 - val_mse: 0.0054 - val_mae: 0.0065\n",
      "Epoch 15/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0122 - mse: 0.0122 - mae: 0.0147 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0062\n",
      "Train MSE = 0.013110432773828506, Validation MSE = 0.006057591177523136, Train MAE = 0.016067199409008026, Validation MAE = 0.0073134396225214005, Train RMSE = 0.11450079813620735, Validation RMSE = 0.07783052857024123\n",
      "Running with 40 LSTM cells, dropout = 0, and learning rate = 0.001...\n",
      "Epoch 1/15\n",
      "1615/1615 [==============================] - 22s 10ms/step - loss: 0.0225 - mse: 0.0225 - mae: 0.0423 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0164\n",
      "Epoch 2/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0151 - mse: 0.0151 - mae: 0.0260 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0118\n",
      "Epoch 3/15\n",
      "1615/1615 [==============================] - 12s 7ms/step - loss: 0.0138 - mse: 0.0138 - mae: 0.0229 - val_loss: 0.0086 - val_mse: 0.0086 - val_mae: 0.0183\n",
      "Epoch 4/15\n",
      "1615/1615 [==============================] - 12s 8ms/step - loss: 0.0130 - mse: 0.0130 - mae: 0.0213 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0090\n",
      "Epoch 5/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0126 - mse: 0.0126 - mae: 0.0202 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0098\n",
      "Epoch 6/15\n",
      "1615/1615 [==============================] - 12s 7ms/step - loss: 0.0122 - mse: 0.0122 - mae: 0.0192 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0112\n",
      "Epoch 7/15\n",
      "1615/1615 [==============================] - 16s 10ms/step - loss: 0.0119 - mse: 0.0119 - mae: 0.0186 - val_loss: 0.0053 - val_mse: 0.0053 - val_mae: 0.0078\n",
      "Epoch 8/15\n",
      "1615/1615 [==============================] - 15s 9ms/step - loss: 0.0117 - mse: 0.0117 - mae: 0.0180 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0111\n",
      "Epoch 9/15\n",
      "1615/1615 [==============================] - 12s 7ms/step - loss: 0.0115 - mse: 0.0115 - mae: 0.0175 - val_loss: 0.0054 - val_mse: 0.0054 - val_mae: 0.0091\n",
      "Epoch 10/15\n",
      "1615/1615 [==============================] - 12s 7ms/step - loss: 0.0113 - mse: 0.0113 - mae: 0.0171 - val_loss: 0.0051 - val_mse: 0.0051 - val_mae: 0.0081\n",
      "Epoch 11/15\n",
      "1615/1615 [==============================] - 12s 7ms/step - loss: 0.0113 - mse: 0.0113 - mae: 0.0167 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0097\n",
      "Epoch 12/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0111 - mse: 0.0111 - mae: 0.0164 - val_loss: 0.0081 - val_mse: 0.0081 - val_mae: 0.0154\n",
      "Epoch 13/15\n",
      "1615/1615 [==============================] - 14s 9ms/step - loss: 0.0110 - mse: 0.0110 - mae: 0.0161 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0083\n",
      "Epoch 14/15\n",
      "1615/1615 [==============================] - 14s 9ms/step - loss: 0.0109 - mse: 0.0109 - mae: 0.0158 - val_loss: 0.0049 - val_mse: 0.0049 - val_mae: 0.0073\n",
      "Epoch 15/15\n",
      "1615/1615 [==============================] - 12s 8ms/step - loss: 0.0108 - mse: 0.0108 - mae: 0.0156 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0078\n",
      "Train MSE = 0.012157121673226357, Validation MSE = 0.005969110876321793, Train MAE = 0.019246211275458336, Validation MAE = 0.011213287711143494, Train RMSE = 0.110259338258609, Validation RMSE = 0.07726002120321863\n",
      "Running with 40 LSTM cells, dropout = 0, and learning rate = 0.01...\n",
      "Epoch 1/15\n",
      "1615/1615 [==============================] - 22s 9ms/step - loss: 0.0244 - mse: 0.0244 - mae: 0.0312 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0116\n",
      "Epoch 2/15\n",
      "1615/1615 [==============================] - 11s 7ms/step - loss: 0.0217 - mse: 0.0217 - mae: 0.0250 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0109\n",
      "Epoch 3/15\n",
      "1615/1615 [==============================] - 14s 9ms/step - loss: 0.0214 - mse: 0.0214 - mae: 0.0243 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0111\n",
      "Epoch 4/15\n",
      "1615/1615 [==============================] - 15s 9ms/step - loss: 0.0212 - mse: 0.0212 - mae: 0.0240 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0101\n",
      "Epoch 5/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0209 - mse: 0.0209 - mae: 0.0237 - val_loss: 0.0090 - val_mse: 0.0090 - val_mae: 0.0099\n",
      "Epoch 6/15\n",
      "1615/1615 [==============================] - 12s 8ms/step - loss: 0.0199 - mse: 0.0199 - mae: 0.0228 - val_loss: 0.0084 - val_mse: 0.0084 - val_mae: 0.0097\n",
      "Epoch 7/15\n",
      "1615/1615 [==============================] - 12s 8ms/step - loss: 0.0193 - mse: 0.0193 - mae: 0.0222 - val_loss: 0.0084 - val_mse: 0.0084 - val_mae: 0.0097\n",
      "Epoch 8/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0188 - mse: 0.0188 - mae: 0.0220 - val_loss: 0.0081 - val_mse: 0.0081 - val_mae: 0.0095\n",
      "Epoch 9/15\n",
      "1615/1615 [==============================] - 14s 9ms/step - loss: 0.0179 - mse: 0.0179 - mae: 0.0211 - val_loss: 0.0081 - val_mse: 0.0081 - val_mae: 0.0090\n",
      "Epoch 10/15\n",
      "1615/1615 [==============================] - 15s 9ms/step - loss: 0.0178 - mse: 0.0178 - mae: 0.0207 - val_loss: 0.0079 - val_mse: 0.0079 - val_mae: 0.0090\n",
      "Epoch 11/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0176 - mse: 0.0176 - mae: 0.0205 - val_loss: 0.0078 - val_mse: 0.0078 - val_mae: 0.0086\n",
      "Epoch 12/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0176 - mse: 0.0176 - mae: 0.0204 - val_loss: 0.0079 - val_mse: 0.0079 - val_mae: 0.0097\n",
      "Epoch 13/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0175 - mse: 0.0175 - mae: 0.0203 - val_loss: 0.0077 - val_mse: 0.0077 - val_mae: 0.0083\n",
      "Epoch 14/15\n",
      "1615/1615 [==============================] - 12s 8ms/step - loss: 0.0175 - mse: 0.0175 - mae: 0.0202 - val_loss: 0.0078 - val_mse: 0.0078 - val_mae: 0.0086\n",
      "Epoch 15/15\n",
      "1615/1615 [==============================] - 16s 10ms/step - loss: 0.0175 - mse: 0.0175 - mae: 0.0203 - val_loss: 0.0078 - val_mse: 0.0078 - val_mae: 0.0092\n",
      "Train MSE = 0.01990416646003723, Validation MSE = 0.008423651568591595, Train MAE = 0.022832494229078293, Validation MAE = 0.00973651371896267, Train RMSE = 0.1410821266498249, Validation RMSE = 0.09178045308556498\n",
      "Running with 40 LSTM cells, dropout = 0.01, and learning rate = 0.001...\n",
      "Epoch 1/15\n",
      "1615/1615 [==============================] - 25s 10ms/step - loss: 0.0230 - mse: 0.0230 - mae: 0.0446 - val_loss: 0.0079 - val_mse: 0.0079 - val_mae: 0.0135\n",
      "Epoch 2/15\n",
      "1615/1615 [==============================] - 14s 9ms/step - loss: 0.0158 - mse: 0.0158 - mae: 0.0266 - val_loss: 0.0071 - val_mse: 0.0071 - val_mae: 0.0121\n",
      "Epoch 3/15\n",
      "1615/1615 [==============================] - 15s 10ms/step - loss: 0.0142 - mse: 0.0142 - mae: 0.0234 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0105\n",
      "Epoch 4/15\n",
      "1615/1615 [==============================] - 16s 10ms/step - loss: 0.0135 - mse: 0.0135 - mae: 0.0217 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0109\n",
      "Epoch 5/15\n",
      "1615/1615 [==============================] - 16s 10ms/step - loss: 0.0131 - mse: 0.0131 - mae: 0.0210 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0119\n",
      "Epoch 6/15\n",
      "1615/1615 [==============================] - 15s 9ms/step - loss: 0.0129 - mse: 0.0129 - mae: 0.0203 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0093\n",
      "Epoch 7/15\n",
      "1615/1615 [==============================] - 16s 10ms/step - loss: 0.0126 - mse: 0.0126 - mae: 0.0197 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0087\n",
      "Epoch 8/15\n",
      "1615/1615 [==============================] - 15s 9ms/step - loss: 0.0124 - mse: 0.0124 - mae: 0.0193 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0095\n",
      "Epoch 9/15\n",
      "1615/1615 [==============================] - 15s 9ms/step - loss: 0.0122 - mse: 0.0122 - mae: 0.0187 - val_loss: 0.0054 - val_mse: 0.0054 - val_mae: 0.0083\n",
      "Epoch 10/15\n",
      "1615/1615 [==============================] - 16s 10ms/step - loss: 0.0121 - mse: 0.0121 - mae: 0.0183 - val_loss: 0.0054 - val_mse: 0.0054 - val_mae: 0.0081\n",
      "Epoch 11/15\n",
      "1615/1615 [==============================] - 15s 9ms/step - loss: 0.0119 - mse: 0.0119 - mae: 0.0179 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0089\n",
      "Epoch 12/15\n",
      "1615/1615 [==============================] - 14s 9ms/step - loss: 0.0118 - mse: 0.0118 - mae: 0.0176 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0073\n",
      "Epoch 13/15\n",
      "1615/1615 [==============================] - 15s 9ms/step - loss: 0.0117 - mse: 0.0117 - mae: 0.0172 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0098\n",
      "Epoch 14/15\n",
      "1615/1615 [==============================] - 15s 9ms/step - loss: 0.0116 - mse: 0.0116 - mae: 0.0170 - val_loss: 0.0051 - val_mse: 0.0051 - val_mae: 0.0074\n",
      "Epoch 15/15\n",
      "1615/1615 [==============================] - 18s 11ms/step - loss: 0.0115 - mse: 0.0115 - mae: 0.0167 - val_loss: 0.0051 - val_mse: 0.0051 - val_mae: 0.0072\n",
      "Train MSE = 0.012899951077997684, Validation MSE = 0.005674823187291622, Train MAE = 0.02032211422920227, Validation MAE = 0.009320437908172607, Train RMSE = 0.11357795154869489, Validation RMSE = 0.07533142231029241\n",
      "Running with 40 LSTM cells, dropout = 0.01, and learning rate = 0.01...\n",
      "Epoch 1/15\n",
      "1615/1615 [==============================] - 22s 10ms/step - loss: 0.0196 - mse: 0.0196 - mae: 0.0281 - val_loss: 0.0071 - val_mse: 0.0071 - val_mae: 0.0088\n",
      "Epoch 2/15\n",
      "1615/1615 [==============================] - 14s 9ms/step - loss: 0.0161 - mse: 0.0161 - mae: 0.0202 - val_loss: 0.0072 - val_mse: 0.0072 - val_mae: 0.0084\n",
      "Epoch 3/15\n",
      "1615/1615 [==============================] - 14s 9ms/step - loss: 0.0156 - mse: 0.0156 - mae: 0.0191 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0092\n",
      "Epoch 4/15\n",
      "1615/1615 [==============================] - 17s 10ms/step - loss: 0.0154 - mse: 0.0154 - mae: 0.0184 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0076\n",
      "Epoch 5/15\n",
      "1615/1615 [==============================] - 17s 10ms/step - loss: 0.0154 - mse: 0.0154 - mae: 0.0181 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0074\n",
      "Epoch 6/15\n",
      "1615/1615 [==============================] - 14s 9ms/step - loss: 0.0153 - mse: 0.0153 - mae: 0.0179 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0074\n",
      "Epoch 7/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0153 - mse: 0.0153 - mae: 0.0176 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0073\n",
      "Epoch 8/15\n",
      "1615/1615 [==============================] - 14s 8ms/step - loss: 0.0152 - mse: 0.0152 - mae: 0.0174 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0076\n",
      "Epoch 9/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0150 - mse: 0.0150 - mae: 0.0174 - val_loss: 0.0145 - val_mse: 0.0145 - val_mae: 0.0192\n",
      "Epoch 10/15\n",
      "1615/1615 [==============================] - 15s 9ms/step - loss: 0.0144 - mse: 0.0144 - mae: 0.0168 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0075\n",
      "Epoch 11/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0141 - mse: 0.0141 - mae: 0.0164 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0071\n",
      "Epoch 12/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0140 - mse: 0.0140 - mae: 0.0163 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0075\n",
      "Epoch 13/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0139 - mse: 0.0139 - mae: 0.0162 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0069\n",
      "Epoch 14/15\n",
      "1615/1615 [==============================] - 12s 8ms/step - loss: 0.0138 - mse: 0.0138 - mae: 0.0161 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0067\n",
      "Epoch 15/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0137 - mse: 0.0137 - mae: 0.0159 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0070\n",
      "Train MSE = 0.015333663672208786, Validation MSE = 0.006725401151925325, Train MAE = 0.017850270494818687, Validation MAE = 0.007376890629529953, Train RMSE = 0.12382917132973469, Validation RMSE = 0.08200854316426628\n",
      "Running with 50 LSTM cells, dropout = 0, and learning rate = 0.001...\n",
      "Epoch 1/15\n",
      "1615/1615 [==============================] - 22s 9ms/step - loss: 0.0223 - mse: 0.0223 - mae: 0.0428 - val_loss: 0.0078 - val_mse: 0.0078 - val_mae: 0.0162\n",
      "Epoch 2/15\n",
      "1615/1615 [==============================] - 12s 7ms/step - loss: 0.0148 - mse: 0.0148 - mae: 0.0249 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0104\n",
      "Epoch 3/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0137 - mse: 0.0137 - mae: 0.0220 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0103\n",
      "Epoch 4/15\n",
      "1615/1615 [==============================] - 14s 8ms/step - loss: 0.0132 - mse: 0.0132 - mae: 0.0206 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0129\n",
      "Epoch 5/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0129 - mse: 0.0129 - mae: 0.0198 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0097\n",
      "Epoch 6/15\n",
      "1615/1615 [==============================] - 15s 9ms/step - loss: 0.0127 - mse: 0.0127 - mae: 0.0193 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0107\n",
      "Epoch 7/15\n",
      "1615/1615 [==============================] - 15s 9ms/step - loss: 0.0125 - mse: 0.0125 - mae: 0.0188 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0088\n",
      "Epoch 8/15\n",
      "1615/1615 [==============================] - 14s 9ms/step - loss: 0.0123 - mse: 0.0123 - mae: 0.0182 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0179\n",
      "Epoch 9/15\n",
      "1615/1615 [==============================] - 14s 9ms/step - loss: 0.0122 - mse: 0.0122 - mae: 0.0179 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0094\n",
      "Epoch 10/15\n",
      "1615/1615 [==============================] - 16s 10ms/step - loss: 0.0120 - mse: 0.0120 - mae: 0.0175 - val_loss: 0.0054 - val_mse: 0.0054 - val_mae: 0.0078\n",
      "Epoch 11/15\n",
      "1615/1615 [==============================] - 15s 10ms/step - loss: 0.0119 - mse: 0.0119 - mae: 0.0172 - val_loss: 0.0054 - val_mse: 0.0054 - val_mae: 0.0084\n",
      "Epoch 12/15\n",
      "1615/1615 [==============================] - 18s 11ms/step - loss: 0.0118 - mse: 0.0118 - mae: 0.0169 - val_loss: 0.0053 - val_mse: 0.0053 - val_mae: 0.0081\n",
      "Epoch 13/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0117 - mse: 0.0117 - mae: 0.0165 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0100\n",
      "Epoch 14/15\n",
      "1615/1615 [==============================] - 17s 11ms/step - loss: 0.0111 - mse: 0.0111 - mae: 0.0164 - val_loss: 0.0050 - val_mse: 0.0050 - val_mae: 0.0072\n",
      "Epoch 15/15\n",
      "1615/1615 [==============================] - 14s 9ms/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0156 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0081\n",
      "Train MSE = 0.012688559480011463, Validation MSE = 0.0060352724976837635, Train MAE = 0.019286323338747025, Validation MAE = 0.010664112865924835, Train RMSE = 0.11264350615997117, Validation RMSE = 0.07768701627481753\n",
      "Running with 50 LSTM cells, dropout = 0, and learning rate = 0.01...\n",
      "Epoch 1/15\n",
      "1615/1615 [==============================] - 21s 9ms/step - loss: 0.0207 - mse: 0.0207 - mae: 0.0301 - val_loss: 0.0073 - val_mse: 0.0073 - val_mae: 0.0106\n",
      "Epoch 2/15\n",
      "1615/1615 [==============================] - 12s 8ms/step - loss: 0.0146 - mse: 0.0146 - mae: 0.0202 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0095\n",
      "Epoch 3/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0125 - mse: 0.0125 - mae: 0.0173 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0072\n",
      "Epoch 4/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0118 - mse: 0.0118 - mae: 0.0160 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0070\n",
      "Epoch 5/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0115 - mse: 0.0115 - mae: 0.0152 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0067\n",
      "Epoch 6/15\n",
      "1615/1615 [==============================] - 15s 9ms/step - loss: 0.0111 - mse: 0.0111 - mae: 0.0150 - val_loss: 0.0053 - val_mse: 0.0053 - val_mae: 0.0067\n",
      "Epoch 7/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0110 - mse: 0.0110 - mae: 0.0146 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0095\n",
      "Epoch 8/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0108 - mse: 0.0108 - mae: 0.0142 - val_loss: 0.0050 - val_mse: 0.0050 - val_mae: 0.0065\n",
      "Epoch 9/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0107 - mse: 0.0107 - mae: 0.0140 - val_loss: 0.0054 - val_mse: 0.0054 - val_mae: 0.0076\n",
      "Epoch 10/15\n",
      "1615/1615 [==============================] - 14s 9ms/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0138 - val_loss: 0.0049 - val_mse: 0.0049 - val_mae: 0.0063\n",
      "Epoch 11/15\n",
      "1615/1615 [==============================] - 15s 9ms/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0136 - val_loss: 0.0048 - val_mse: 0.0048 - val_mae: 0.0080\n",
      "Epoch 12/15\n",
      "1615/1615 [==============================] - 14s 9ms/step - loss: 0.0103 - mse: 0.0103 - mae: 0.0134 - val_loss: 0.0046 - val_mse: 0.0046 - val_mae: 0.0061\n",
      "Epoch 13/15\n",
      "1615/1615 [==============================] - 12s 8ms/step - loss: 0.0102 - mse: 0.0102 - mae: 0.0131 - val_loss: 0.0047 - val_mse: 0.0047 - val_mae: 0.0069\n",
      "Epoch 14/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0101 - mse: 0.0101 - mae: 0.0130 - val_loss: 0.0048 - val_mse: 0.0048 - val_mae: 0.0068\n",
      "Epoch 15/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0100 - mse: 0.0100 - mae: 0.0130 - val_loss: 0.0045 - val_mse: 0.0045 - val_mae: 0.0061\n",
      "Train MSE = 0.011118789203464985, Validation MSE = 0.005264605861157179, Train MAE = 0.015004669316112995, Validation MAE = 0.006712821312248707, Train RMSE = 0.10544566943912388, Validation RMSE = 0.07255760374459164\n",
      "Running with 50 LSTM cells, dropout = 0.01, and learning rate = 0.001...\n",
      "Epoch 1/15\n",
      "1615/1615 [==============================] - 25s 12ms/step - loss: 0.0247 - mse: 0.0247 - mae: 0.0442 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0165\n",
      "Epoch 2/15\n",
      "1615/1615 [==============================] - 16s 10ms/step - loss: 0.0185 - mse: 0.0185 - mae: 0.0294 - val_loss: 0.0085 - val_mse: 0.0085 - val_mae: 0.0167\n",
      "Epoch 3/15\n",
      "1615/1615 [==============================] - 18s 11ms/step - loss: 0.0166 - mse: 0.0166 - mae: 0.0264 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0105\n",
      "Epoch 4/15\n",
      "1615/1615 [==============================] - 17s 10ms/step - loss: 0.0146 - mse: 0.0146 - mae: 0.0238 - val_loss: 0.0084 - val_mse: 0.0084 - val_mae: 0.0186\n",
      "Epoch 5/15\n",
      "1615/1615 [==============================] - 16s 10ms/step - loss: 0.0137 - mse: 0.0137 - mae: 0.0226 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0094\n",
      "Epoch 6/15\n",
      "1615/1615 [==============================] - 17s 11ms/step - loss: 0.0131 - mse: 0.0131 - mae: 0.0215 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0097\n",
      "Epoch 7/15\n",
      "1615/1615 [==============================] - 15s 9ms/step - loss: 0.0128 - mse: 0.0128 - mae: 0.0207 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0085\n",
      "Epoch 8/15\n",
      "1615/1615 [==============================] - 14s 9ms/step - loss: 0.0122 - mse: 0.0122 - mae: 0.0199 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0087\n",
      "Epoch 9/15\n",
      "1615/1615 [==============================] - 16s 10ms/step - loss: 0.0120 - mse: 0.0120 - mae: 0.0192 - val_loss: 0.0053 - val_mse: 0.0053 - val_mae: 0.0084\n",
      "Epoch 10/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0118 - mse: 0.0118 - mae: 0.0187 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0080\n",
      "Epoch 11/15\n",
      "1615/1615 [==============================] - 19s 11ms/step - loss: 0.0113 - mse: 0.0113 - mae: 0.0186 - val_loss: 0.0051 - val_mse: 0.0051 - val_mae: 0.0084\n",
      "Epoch 12/15\n",
      "1615/1615 [==============================] - 17s 10ms/step - loss: 0.0108 - mse: 0.0108 - mae: 0.0179 - val_loss: 0.0049 - val_mse: 0.0049 - val_mae: 0.0076\n",
      "Epoch 13/15\n",
      "1615/1615 [==============================] - 18s 11ms/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0173 - val_loss: 0.0053 - val_mse: 0.0053 - val_mae: 0.0098\n",
      "Epoch 14/15\n",
      "1615/1615 [==============================] - 18s 11ms/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0168 - val_loss: 0.0047 - val_mse: 0.0047 - val_mae: 0.0072\n",
      "Epoch 15/15\n",
      "1615/1615 [==============================] - 13s 8ms/step - loss: 0.0102 - mse: 0.0102 - mae: 0.0164 - val_loss: 0.0048 - val_mse: 0.0048 - val_mae: 0.0075\n",
      "Train MSE = 0.01313325297087431, Validation MSE = 0.005970918573439121, Train MAE = 0.021509235724806786, Validation MAE = 0.00968785397708416, Train RMSE = 0.11460040563136899, Validation RMSE = 0.07727171910498123\n",
      "Running with 50 LSTM cells, dropout = 0.01, and learning rate = 0.01...\n",
      "Epoch 1/15\n",
      "1615/1615 [==============================] - 21s 10ms/step - loss: 0.0216 - mse: 0.0216 - mae: 0.0299 - val_loss: 0.0078 - val_mse: 0.0078 - val_mae: 0.0093\n",
      "Epoch 2/15\n",
      "1615/1615 [==============================] - 18s 11ms/step - loss: 0.0169 - mse: 0.0169 - mae: 0.0219 - val_loss: 0.0072 - val_mse: 0.0072 - val_mae: 0.0089\n",
      "Epoch 3/15\n",
      "1615/1615 [==============================] - 18s 11ms/step - loss: 0.0155 - mse: 0.0155 - mae: 0.0196 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0090\n",
      "Epoch 4/15\n",
      "1615/1615 [==============================] - 14s 9ms/step - loss: 0.0153 - mse: 0.0153 - mae: 0.0189 - val_loss: 0.0072 - val_mse: 0.0072 - val_mae: 0.0091\n",
      "Epoch 5/15\n",
      "1615/1615 [==============================] - 17s 11ms/step - loss: 0.0151 - mse: 0.0151 - mae: 0.0184 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0074\n",
      "Epoch 6/15\n",
      "1615/1615 [==============================] - 17s 10ms/step - loss: 0.0149 - mse: 0.0149 - mae: 0.0180 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0078\n",
      "Epoch 7/15\n",
      "1615/1615 [==============================] - 17s 11ms/step - loss: 0.0146 - mse: 0.0146 - mae: 0.0180 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0096\n",
      "Epoch 8/15\n",
      "1615/1615 [==============================] - 16s 10ms/step - loss: 0.0138 - mse: 0.0138 - mae: 0.0173 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0077\n",
      "Epoch 9/15\n",
      "1615/1615 [==============================] - 16s 10ms/step - loss: 0.0135 - mse: 0.0135 - mae: 0.0167 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0078\n",
      "Epoch 10/15\n",
      "1615/1615 [==============================] - 17s 11ms/step - loss: 0.0135 - mse: 0.0135 - mae: 0.0164 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0083\n",
      "Epoch 11/15\n",
      "1615/1615 [==============================] - 19s 12ms/step - loss: 0.0134 - mse: 0.0134 - mae: 0.0162 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0093\n",
      "Epoch 12/15\n",
      "1615/1615 [==============================] - 17s 10ms/step - loss: 0.0133 - mse: 0.0133 - mae: 0.0161 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0075\n",
      "Epoch 13/15\n",
      "1615/1615 [==============================] - 14s 8ms/step - loss: 0.0132 - mse: 0.0132 - mae: 0.0159 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0084\n",
      "Epoch 14/15\n",
      "1615/1615 [==============================] - 18s 11ms/step - loss: 0.0131 - mse: 0.0131 - mae: 0.0157 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0070\n",
      "Epoch 15/15\n",
      "1615/1615 [==============================] - 15s 9ms/step - loss: 0.0131 - mse: 0.0131 - mae: 0.0156 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0068\n",
      "Train MSE = 0.014941975474357605, Validation MSE = 0.006601274013519287, Train MAE = 0.018039753660559654, Validation MAE = 0.007771751377731562, Train RMSE = 0.1222373734761902, Validation RMSE = 0.08124822467918476\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "sequence_length = X_train_reshaped1.shape[1]\n",
    "nb_features = X_train_reshaped1.shape[2]\n",
    "for num_cells in [30, 40, 50]:\n",
    "    for dropout_rate in [0, 0.01]:\n",
    "        for learning_rate in [ 1e-3, 1e-2]:\n",
    "            print(f'Running with {num_cells} LSTM cells, dropout = {dropout_rate}, and learning rate = {learning_rate}...')\n",
    "            \n",
    "            model = Sequential([\n",
    "                LSTM(units=num_cells, return_sequences=True, input_shape=(sequence_length, nb_features)),\n",
    "                Dropout(dropout_rate),\n",
    "                LSTM(units=num_cells, return_sequences=False),\n",
    "                Dropout(dropout_rate),\n",
    "                Dense(units=1, activation='relu')\n",
    "            ])  \n",
    "            optimiser = RMSprop(learning_rate=learning_rate)\n",
    "            model.compile(loss=\"mse\", optimizer=optimiser, metrics=['mse', 'mae'])\n",
    "            history = model.fit(X_train_reshaped1, target_train, epochs=15, batch_size=200, validation_data=(X_test_reshaped1, target_test), verbose=1, callbacks=[EarlyStopping(monitor='val_loss', patience=10)])\n",
    "\n",
    "            num_epochs = len(history.history['val_loss'])\n",
    "            best_epoch = num_epochs - 10\n",
    "            train_mse = history.history['loss'][best_epoch]\n",
    "            val_mse = history.history['val_loss'][best_epoch]\n",
    "            train_mae = history.history['mae'][best_epoch]\n",
    "            val_mae = history.history['val_mae'][best_epoch]\n",
    "            train_rmse = math.sqrt(train_mse)\n",
    "            val_rmse = math.sqrt(val_mse)\n",
    "            results[(num_cells, dropout_rate, learning_rate, best_epoch)] = {'train_mse': train_mse, 'val_mse': val_mse, 'train_mae': train_mae, 'val_mae': val_mae, 'train_rmse': train_rmse, 'val_rmse': val_rmse}           \n",
    "            print(f'Train MSE = {train_mse}, Validation MSE = {val_mse}, Train MAE = {train_mae}, Validation MAE = {val_mae}, Train RMSE = {train_rmse}, Validation RMSE = {val_rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2a81759-f70c-46cb-9e14-613de445562b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: 30 LSTM cells, training for 5 epochs with dropout = 0 and learning rate = 0.01\n"
     ]
    }
   ],
   "source": [
    "val_results = {key: results[key]['val_mse'] for key in results.keys()}\n",
    "num_cells, dropout_rate, learning_rate, num_epochs = min(val_results, key=val_results.get)\n",
    "print(f'Best parameters: {num_cells} LSTM cells, training for {num_epochs} epochs with dropout = {dropout_rate} and learning rate = {learning_rate}')\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(units=num_cells, return_sequences=True, input_shape=(sequence_length, nb_features)),\n",
    "    Dropout(dropout_rate),\n",
    "    LSTM(units=num_cells, return_sequences=False),\n",
    "    Dropout(dropout_rate),\n",
    "    Dense(units=1, activation='relu')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f15f8b38-1308-41e0-9411-5372e85ba82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1615/1615 [==============================] - 17s 7ms/step - loss: 0.0177 - mse: 0.0177 - mae: 0.0268 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0090\n",
      "Epoch 2/10\n",
      "1615/1615 [==============================] - 9s 6ms/step - loss: 0.0137 - mse: 0.0137 - mae: 0.0186 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0090\n",
      "Epoch 3/10\n",
      "1615/1615 [==============================] - 9s 6ms/step - loss: 0.0133 - mse: 0.0133 - mae: 0.0174 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0076\n",
      "Epoch 4/10\n",
      "1615/1615 [==============================] - 9s 6ms/step - loss: 0.0129 - mse: 0.0129 - mae: 0.0167 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0094\n",
      "Epoch 5/10\n",
      "1615/1615 [==============================] - 9s 6ms/step - loss: 0.0126 - mse: 0.0126 - mae: 0.0164 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0071\n",
      "Epoch 6/10\n",
      "1615/1615 [==============================] - 9s 6ms/step - loss: 0.0123 - mse: 0.0123 - mae: 0.0158 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0067\n",
      "Epoch 7/10\n",
      "1615/1615 [==============================] - 10s 6ms/step - loss: 0.0122 - mse: 0.0122 - mae: 0.0154 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0094\n",
      "Epoch 8/10\n",
      "1615/1615 [==============================] - 9s 6ms/step - loss: 0.0121 - mse: 0.0121 - mae: 0.0152 - val_loss: 0.0054 - val_mse: 0.0054 - val_mae: 0.0066\n",
      "Epoch 9/10\n",
      "1615/1615 [==============================] - 10s 6ms/step - loss: 0.0120 - mse: 0.0120 - mae: 0.0150 - val_loss: 0.0054 - val_mse: 0.0054 - val_mae: 0.0063\n",
      "Epoch 10/10\n",
      "1615/1615 [==============================] - 9s 6ms/step - loss: 0.0120 - mse: 0.0120 - mae: 0.0150 - val_loss: 0.0054 - val_mse: 0.0054 - val_mae: 0.0062\n"
     ]
    }
   ],
   "source": [
    "optimiser = RMSprop(learning_rate=learning_rate)\n",
    "model.compile(loss=\"mse\", optimizer=optimiser, metrics=['mse', 'mae'])\n",
    "hist = model.fit(X_train_reshaped1, target_train, epochs=10, batch_size=200, validation_data=(X_test_reshaped1, target_test), verbose=1, callbacks=[EarlyStopping(monitor='val_loss', patience=10)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "849cb87f-1206-414b-9c1f-8f7299eb0938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5806/5806 - 11s - loss: 0.0054 - mse: 0.0054 - mae: 0.0062 - 11s/epoch - 2ms/step\n",
      "MSE: 0.005362235475331545, MAE: 0.006198440212756395, RMSE: 0.07322728641245382\n"
     ]
    }
   ],
   "source": [
    "scores_test = model.evaluate(X_test_reshaped1, target_test, verbose=2)\n",
    "rmse_test = math.sqrt(scores_test[1])\n",
    "print(f'MSE: {scores_test[1]}, MAE: {scores_test[2]}, RMSE: {rmse_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48c4be05-e1f1-4375-afef-133bd9d53130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(hist.history['mse'])\n",
    "plt.plot(hist.history['val_mse'])\n",
    "plt.title('MSE')\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('# Epoch')\n",
    "plt.legend(['Train MSE', 'Validation MSE'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c3580cd-5058-4fab-83cf-baa63b6c35f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(hist.history['mae'])\n",
    "plt.plot(hist.history['val_mae'])\n",
    "plt.title('MAE')\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('# Epoch')\n",
    "plt.legend([ 'Train MAE', 'Validation MAE'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a9737bb-1a27-4b95-b1c3-21e38e9595fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5806/5806 [==============================] - 10s 2ms/step\n",
      "Accuracy: 0.9883\n",
      "Precision: 1.0000\n",
      "Recall: 0.7982\n",
      "F1 Score: 0.8878\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = model.predict(X_test_reshaped1)\n",
    "y_pred_binary = (y_pred_test > 0.99).astype(int)\n",
    "accuracy = accuracy_score(target_test, y_pred_binary)\n",
    "precision = precision_score(target_test, y_pred_binary)\n",
    "recall = recall_score(target_test, y_pred_binary)\n",
    "f1 = f1_score(target_test, y_pred_binary)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25adfa93-b6a2-4c16-9b67-fcd89f5190bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
